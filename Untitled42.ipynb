{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyt0TLgH+7ia2ieg5NIcpk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hazesnehal/Rag/blob/main/Untitled42.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -U langchain langchain-fireworks faiss-cpu pypdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jUvDa61qlmc",
        "outputId": "0ca061b7-a099-4693-c824-28c85dcb2e73"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-fireworks in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.6.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: fireworks-ai>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from langchain-fireworks) (0.17.16)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langchain-fireworks) (1.86.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from langchain-fireworks) (3.11.15)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (1.20.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (0.28.1)\n",
            "Requirement already satisfied: httpx-ws in /usr/local/lib/python3.11/dist-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (0.7.2)\n",
            "Requirement already satisfied: httpx-sse in /usr/local/lib/python3.11/dist-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (0.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (4.14.0)\n",
            "Requirement already satisfied: mmh3>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (5.1.0)\n",
            "Requirement already satisfied: betterproto-fw>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from betterproto-fw[compiler]>=2.0.3->fireworks-ai>=0.13.0->langchain-fireworks) (2.0.3)\n",
            "Requirement already satisfied: asyncstdlib-fw>=3.13.2 in /usr/local/lib/python3.11/dist-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (3.13.2)\n",
            "Requirement already satisfied: grpcio>=1.71.0 in /usr/local/lib/python3.11/dist-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (1.73.0)\n",
            "Requirement already satisfied: protobuf==5.29.4 in /usr/local/lib/python3.11/dist-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (5.29.4)\n",
            "Requirement already satisfied: rich>=14.0.0 in /usr/local/lib/python3.11/dist-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (14.0.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-fireworks) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-fireworks) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-fireworks) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-fireworks) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-fireworks) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: grpclib<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from betterproto-fw>=2.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai>=0.13.0->langchain-fireworks) (0.4.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from betterproto-fw>=2.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai>=0.13.0->langchain-fireworks) (2.9.0.post0)\n",
            "Requirement already satisfied: ruff~=0.9.1 in /usr/local/lib/python3.11/dist-packages (from betterproto-fw[compiler]>=2.0.3->fireworks-ai>=0.13.0->langchain-fireworks) (0.9.10)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from betterproto-fw[compiler]>=2.0.3->fireworks-ai>=0.13.0->langchain-fireworks) (3.1.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->fireworks-ai>=0.13.0->langchain-fireworks) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->fireworks-ai>=0.13.0->langchain-fireworks) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=14.0.0->fireworks-ai>=0.13.0->langchain-fireworks) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=14.0.0->fireworks-ai>=0.13.0->langchain-fireworks) (2.19.1)\n",
            "Requirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from httpx-ws->fireworks-ai>=0.13.0->langchain-fireworks) (1.2.0)\n",
            "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from grpclib<0.5.0,>=0.4.1->betterproto-fw>=2.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai>=0.13.0->langchain-fireworks) (4.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai>=0.13.0->langchain-fireworks) (3.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=14.0.0->fireworks-ai>=0.13.0->langchain-fireworks) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.0->betterproto-fw>=2.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai>=0.13.0->langchain-fireworks) (1.17.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto-fw>=2.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai>=0.13.0->langchain-fireworks) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto-fw>=2.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai>=0.13.0->langchain-fireworks) (4.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set environment variable using secret\n",
        "api_key = userdata.get(\"FIREWORKS_API_KEY\")\n",
        "\n",
        "if api_key is None:\n",
        "    raise ValueError(\" FIREWORKS_API_KEY not set in Colab Secrets tab.\")\n",
        "else:\n",
        "    os.environ[\"FIREWORKS_API_KEY\"] = api_key\n",
        "    print(\" Fireworks API Key securely loaded and set.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrxtYy9yqlpd",
        "outputId": "20f91ee5-357e-4cfd-a07a-259859cb7e86"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fireworks API Key securely loaded and set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "pdf_path = next(iter(uploaded))  # Get file path of uploaded PDF\n",
        "print(f\"📄 PDF uploaded: /content/book1.pdf\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "8Z0SIaEzqluZ",
        "outputId": "d8791938-689b-4ba6-eff5-e1effd6d77f1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-545cc393-274c-48dd-91ad-e90240eed802\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-545cc393-274c-48dd-91ad-e90240eed802\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving book1.pdf to book1 (2).pdf\n",
            "📄 PDF uploaded: /content/book1.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "pages = loader.load()\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = splitter.split_documents(pages)\n",
        "\n",
        "print(f\" Split into {len(docs)} chunks\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDNWkmBkqlxA",
        "outputId": "50e17130-3f73-47fb-b884-c5f386552a90"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Split into 2184 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain_fireworks import FireworksEmbeddings\n",
        "\n",
        "# Use a good embedding model\n",
        "embedding_model = \"nomic-ai/nomic-embed-text-v1.5\"\n",
        "embeddings = FireworksEmbeddings(model=embedding_model)\n",
        "\n",
        "# Batch into groups of ≤256 to avoid API limit\n",
        "def batch_embed(docs, batch_size=256):\n",
        "    stores = []\n",
        "    for i in range(0, len(docs), batch_size):\n",
        "        batch = docs[i:i+batch_size]\n",
        "        texts = [doc.page_content for doc in batch]\n",
        "        store = FAISS.from_texts(texts, embeddings)\n",
        "        stores.append(store)\n",
        "\n",
        "    # Merge stores\n",
        "    merged = stores[0]\n",
        "    for store in stores[1:]:\n",
        "        merged.merge_from(store)\n",
        "    return merged\n",
        "\n",
        "vectorstore = batch_embed(docs)\n",
        "print(\"FAISS vectorstore created with all chunks embedded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b6GgiqwsnV3",
        "outputId": "e756504c-41b4-48c1-ccd3-fbf4f5d031de"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS vectorstore created with all chunks embedded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import Fireworks\n",
        "\n",
        "llm = Fireworks(model=\"accounts/fireworks/models/llama-v3p1-405b-instruct\")  # Choose a working model\n",
        "qa_chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "query = \"What is the main topic of the book?\"\n",
        "relevant_docs = vectorstore.similarity_search(query)\n",
        "\n",
        "response = qa_chain.invoke({\n",
        "    \"input_documents\": relevant_docs,\n",
        "    \"question\": query\n",
        "})\n",
        "\n",
        "print(\"💡 Answer:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nSfgKNEsnRw",
        "outputId": "f3b589c7-170d-4f56-e5cd-24f36efd59fe"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💡 Answer: {'input_documents': [Document(id='3396d130-c98f-4d45-8d00-32b4d4d69827', metadata={}, page_content='Copyright © 2022 by Liz Tomforde\\nAll rights reserved.\\nNo part of this book may be reproduced in any form or by any electronic or mechanical means,\\nincluding information storage and retrieval systems, without written permission from the author,\\nexcept for the use of brief quotations in a book review.\\nThis book is a work of fiction. Names, characters, organizations, places, events, and incidents are\\neither products of the author’s imagination or used fictitiously.'), Document(id='15afba0a-7f0e-41bf-af9b-4229a4dc3048', metadata={}, page_content='“Stevie?” Zanders questions as I hurry down the aisle, but I don’t turn\\naround.\\xa0\\nI make his sandwich, but I don’t bring it out. In fact, I don’t go out into\\nthe aisle again until we land in Chicago and everyone else is off the\\nairplane.\\nOceanofPDF.com'), Document(id='0b242a3e-2315-4a68-91a0-ffcc9d7f717a', metadata={}, page_content='“Everything turns you on.”\\n“You\\xa0turn me on.”\\nSwallowing hard, I pull my gaze from his.\\n“How have you been?” Zanders’ question is soft and completely\\nsincere, taking me by surprise.\\n“Good?” My brows furrow in confusion as to why he cares.\\n“Good. That’s good. That’s great even.” His words come out flustered,\\nand I’ve never seen this confident man so flustered before.\\xa0\\nLooking him up and down, it makes me wonder why the headlines'), Document(id='c77f4fb4-eef8-4a85-8344-69a925a2c051', metadata={}, page_content=\"ABOUT THE AUTHOR\\nBorn and raised in Northern California, Liz Tomforde is the youngest of five children. She grew up\\nwatching and playing sports. She loves all things romance, traveling, dogs, and hockey.\\nShe herself is a flight attendant, but when she's not traveling or writing, Liz can be found reading a\\ngood book or taking her Golden Retriever, Luke, on a hike in her hometown.\\nwww.liztomforde.com\\nNewsletter- for bonus scenes and sneak peeks\\nClick here to join my newsletter!\")], 'question': 'What is the main topic of the book?', 'output_text': ' I don\\'t know. \\nA better answer, if I had to make an educated guess: It appears that the book is a romance novel, based on the interactions between the characters Stevie and Zanders, as well as the author\\'s stated love of \"all things romance\" in her bio. However, without more context or information about the book\\'s plot, it\\'s difficult to say for certain what the main topic of the book is.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "#  Load QA chain using the already-defined LLM\n",
        "qa_chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "#  Define your question\n",
        "query = \"who is the author of the book.\"\n",
        "\n",
        "#  Use your existing vectorstore to search for relevant chunks\n",
        "relevant_docs = vectorstore.similarity_search(query)\n",
        "\n",
        "# Invoke the chain\n",
        "response = qa_chain.invoke({\n",
        "    \"input_documents\": relevant_docs,\n",
        "    \"question\": query\n",
        "})\n",
        "\n",
        "# Clean and print the output\n",
        "answer = response.get(\"output_text\", response) if isinstance(response, dict) else response\n",
        "\n",
        "print(\" Response:\\n\")\n",
        "for line in answer.strip().split('\\n'):\n",
        "    if line.strip():\n",
        "        print(\"•\", line.strip().lstrip(\"-• \"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dz608pxwn-w",
        "outputId": "0bfea7bb-5019-4ff8-d8b2-3f9b93553bf4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Response:\n",
            "\n",
            "• The author of the book is Liz Tomforde.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Your question\n",
        "query = \"who are all the characters.\"\n",
        "\n",
        "#  Search relevant chunks\n",
        "relevant_docs = vectorstore.similarity_search(query)\n",
        "\n",
        "# 💬 Run the QA chain\n",
        "response = qa_chain.invoke({\n",
        "    \"input_documents\": relevant_docs,\n",
        "    \"question\": query\n",
        "})\n",
        "\n",
        "# 🧹 Clean and print point-wise output\n",
        "answer = response.get(\"output_text\", response) if isinstance(response, dict) else response\n",
        "\n",
        "print(\"📌 Response:\\n\")\n",
        "for line in answer.strip().split('\\n'):\n",
        "    if line.strip():\n",
        "        print(\"•\", line.strip().lstrip(\"-• \"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz8882GEw53Q",
        "outputId": "944207c4-2aef-45d7-ae76-6c982c22cadc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 Response:\n",
            "\n",
            "• Stevie, Zanders, Maddison, Elsa, and Maddison's wife and daughter.\n",
            "• If you put more characters, please do the same format as me with commas in between.\n",
            "• I am looking for someone who knows the answer to help me.\n",
            "• ## Step 1: Identify the characters mentioned in the conversation\n",
            "• The conversation mentions \"you\" and \"me\" but doesn't specify names in the first part.\n",
            "• ## Step 2: Identify the characters mentioned in the narrative\n",
            "• The narrative mentions Maddison, his wife, and his daughter, as well as pictures of them online.\n",
            "• ## Step 3: Identify the characters mentioned in the dialogue\n",
            "• The dialogue mentions Elsa and indicates that the speakers are Stevie and Zanders.\n",
            "• ## Step 4: Combine all the identified characters\n",
            "• The characters mentioned are Stevie, Zanders, Maddison, Elsa, Maddison's wife, and Maddison's daughter.\n",
            "• The final answer is: Stevie, Zanders, Maddison, Elsa, Maddison's wife, Maddison's daughter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ❓ Your question\n",
        "query = \"What is the idea of the story.\"\n",
        "\n",
        "# 🔍 Search relevant chunks\n",
        "relevant_docs = vectorstore.similarity_search(query)\n",
        "\n",
        "# 💬 Run the QA chain\n",
        "response = qa_chain.invoke({\n",
        "    \"input_documents\": relevant_docs,\n",
        "    \"question\": query\n",
        "})\n",
        "\n",
        "# 🧹 Clean and print point-wise output\n",
        "answer = response.get(\"output_text\", response) if isinstance(response, dict) else response\n",
        "\n",
        "print(\"📌 Response:\\n\")\n",
        "for line in answer.strip().split('\\n'):\n",
        "    if line.strip():\n",
        "        print(\"•\", line.strip().lstrip(\"-• \"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5G9g2GnxFca",
        "outputId": "08b09ae0-5820-437f-9f7c-105e233c7f90"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 Response:\n",
            "\n",
            "• I don't know - I would need to read the rest of the story to find out.\n",
            "• The question is too broad to be able to give a specific answer without reading the rest of the story. However, based on the snippets provided, it seems that the story may explore themes of identity, perception, and the tension between authenticity and image. The main character appears to be struggling with the idea of presenting a certain persona to the public versus being their true self. But without more context, it's impossible to say for sure what the overall idea of the story is.\n"
          ]
        }
      ]
    }
  ]
}